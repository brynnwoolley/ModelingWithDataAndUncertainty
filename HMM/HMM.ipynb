{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volume 3: Discrete Hidden Markov Models\n",
    "    <Name>\n",
    "    <Class>\n",
    "    <Date>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import string\n",
    "import codecs\n",
    "#from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problems 1-5\n",
    "This is the HMM class that you will be adding functions to throughout the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HMM(object):\n",
    "    \"\"\"\n",
    "    Finite state space hidden Markov model.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Problem 1\n",
    "    def __init__(self, A, B, pi):\n",
    "        \"\"\"\n",
    "        Initialize an HMM with parameters A, B, and pi.\n",
    "        \"\"\"\n",
    "        # initialize\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        self.pi = pi\n",
    "    \n",
    "    # Problem 2\n",
    "    def forward_pass(self, z):\n",
    "        \"\"\"\n",
    "        Compute the forward probability matrix.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        alpha : ndarray of shape (T, n)\n",
    "            The forward probability matrix\n",
    "        \"\"\"\n",
    "        # initialize\n",
    "        T = len(z)  # observation sequence length\n",
    "        n = self.A.shape[0]  # number of states\n",
    "        alpha = np.zeros((T, n))  # forward probability matrix\n",
    "\n",
    "        # compute alpha[0] for all states \n",
    "        alpha[0] = self.pi * self.B[z[0], :]\n",
    "\n",
    "        # calculate alpha[t] for t > 0\n",
    "        for t in range(1, T):\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    alpha[t, i] += alpha[t-1, j] * self.A[i, j]\n",
    "                alpha[t, i] *= self.B[z[t], i] \n",
    "\n",
    "        return alpha\n",
    "    \n",
    "    # Problem 4\n",
    "    def backward_pass(self, z):\n",
    "        \"\"\"\n",
    "        Compute the backward probability matrix and gamma values.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        beta : ndarray of shape (T, n)\n",
    "            The backward probability matrix\n",
    "        gamma : ndarray of shape (T, n)\n",
    "            The state probability matrix\n",
    "        \"\"\"\n",
    "        # initialize\n",
    "        T = len(z)  # observation sequence length\n",
    "        n = self.A.shape[0]  # number of states\n",
    "        beta = np.zeros((T, n))  # backward probability matrix\n",
    "        beta[-1] = 1\n",
    "        gamma = np.zeros((T, n))  # state probability matrix\n",
    "\n",
    "        # calculate P(z|θ) using forward pass\n",
    "        alpha = self.forward_pass(z)\n",
    "        P_z_theta = np.sum(alpha[-1,:])        \n",
    "\n",
    "        # recursive step computing beta[t] for t < T-1\n",
    "        for t in range(T-2, -1, -1):\n",
    "            for j in range(n):\n",
    "                for i in range(n):\n",
    "                    beta[t, j] += self.A[i, j] * beta[t+1, i] * self.B[z[t+1], i] \n",
    "                    \n",
    "        # compute gamma values\n",
    "        for t in range(T):\n",
    "            for i in range(n):\n",
    "                gamma[t, i] = alpha[t, i] * beta[t, i] / P_z_theta\n",
    "                \n",
    "        return beta, gamma\n",
    "    \n",
    "    # Problem 5\n",
    "    def viterbi_algorithm(self, z):\n",
    "        \"\"\"\n",
    "        Compute the most likely hidden state sequence using the Viterbi algorithm.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        z : ndarray of shape (T,)\n",
    "            The observation sequence\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        x*: ndarray of shape (T,)\n",
    "            The most likely state sequence\n",
    "        \"\"\"\n",
    "        # initialize\n",
    "        T = len(z)  # observation sequence length\n",
    "        n = self.A.shape[0]  # number of states\n",
    "        xstar = np.zeros(T, dtype=int)  # most likely state sequence\n",
    "\n",
    "        eta = np.zeros((T, n))\n",
    "        for i in range(n):\n",
    "            eta[0, i] = self.B[z[0], i] * self.pi[i]\n",
    "        \n",
    "        for t in range(1, T):\n",
    "            for i in range(n):\n",
    "                eta[t, i] = np.max(self.B[z[t],i] * self.A[:,i] * eta[t-1])\n",
    "        \n",
    "        xstar[-1] = np.argmax(eta[-1])\n",
    "        \n",
    "        for t in range(T-2, -1, -1):\n",
    "            xstar[t] = np.argmax(eta[t,:] * self.A[xstar[t+1], :])\n",
    "            \n",
    "        return xstar\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 test case\n",
    "\n",
    "Use the following HMM and code to test your HMM class.\n",
    "Compare the output to `forward_pass` with the lab pdf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009629599999999997\n"
     ]
    }
   ],
   "source": [
    "pi = np.array([.6, .4])\n",
    "A = np.array([[.7, .4],[.3, .6]])\n",
    "B = np.array([[.1,.7],[.4, .2],[.5, .1]])\n",
    "z_example = np.array([0, 1, 0, 2])\n",
    "example_hmm = HMM(A, B, pi)\n",
    "\n",
    "alpha=example_hmm.forward_pass(z_example)\n",
    "print(np.sum(alpha[-1,:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3\n",
    "\n",
    "Consider the following (very simplified) model of the price of a stock over time as an HMM.\n",
    "The observation states will be the change in the value of the stock.\n",
    "For simplicity, we will group these into five values: large decrease, small decrease, no change, small increase, large increase, labeled as integers from 0 to 4.\n",
    "The hidden state will be the overall trends of the market.\n",
    "We'll consider the market to have three possible states: declining in value (bear market), not changing in value (stagnant), and increasing in value (bull market), labeled as integers from 0 to 2.\n",
    "Let the HMM modeling this scenario have parameters\n",
    "$$\n",
    "\\boldsymbol\\pi=\\begin{bmatrix}\n",
    "1/3 \\\\ 1/3 \\\\ 1/3\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "A=\\begin{bmatrix}\n",
    "0.5 & 0.3 & 0 \\\\\n",
    "0.5 & 0.3 & 0.3 \\\\\n",
    "0 & 0.4 & 0.7\n",
    "\\end{bmatrix},\n",
    "\\quad\n",
    "B=\\begin{bmatrix}\n",
    "0.3 & 0.1 & 0 \\\\\n",
    "0.3 & 0.2 & 0.1 \\\\\n",
    "0.3 & 0.4 & 0.3 \\\\\n",
    "0.1 & 0.2 & 0.4 \\\\\n",
    "0 & 0.1 & 0.2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "The file `stocks.npy` contains a sequence of 50 observations drawn from this HMM.\n",
    "What is the probability of this observation sequence given these model parameters?\n",
    "Use your implementation of the forward pass algorithm from Problem 2 to find the answer.\n",
    "Note that the answer is very small, because there are lots of possible observation sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM parameter setup\n",
    "pi = np.array([1/3, 1/3, 1/3])\n",
    "A = np.array([\n",
    "    [0.5, 0.3, 0.0],\n",
    "    [0.5, 0.3, 0.3],\n",
    "    [0.0, 0.4, 0.7]\n",
    "])\n",
    "B = np.array([\n",
    "    [0.3, 0.1, 0.0],\n",
    "    [0.3, 0.2, 0.1],\n",
    "    [0.3, 0.4, 0.3],\n",
    "    [0.1, 0.2, 0.4],\n",
    "    [0.0, 0.1, 0.2]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.671115114537777e-34\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "z = np.load('stocks.npy')\n",
    "# build model\n",
    "stock_hmm = HMM(A, B, pi)\n",
    "prob = stock_hmm.forward_pass(z)[-1].sum()\n",
    "print(prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4\n",
    "\n",
    "Create a method `backward_pass` in your HMM class to implement the backward pass algorithm.\n",
    "This function should accept the observation sequence $\\mathbf{z}$ and return two arrays of the $\\beta_t(i)$ and $\\gamma_t(i)$ values.\n",
    "\n",
    "Test your function on the example HMM, and compare the output with the lab pdf.\n",
    "\n",
    "With your function and the stock model from Problem 3, answer the following question: given the observation sequence in `stocks.npy`, what is the most likely initial hidden state $X_0$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0302  0.02792]\n",
      " [0.0812  0.1244 ]\n",
      " [0.38    0.26   ]\n",
      " [1.      1.     ]]\n",
      "[[0.18816981 0.81183019]\n",
      " [0.51943175 0.48056825]\n",
      " [0.22887763 0.77112237]\n",
      " [0.8039794  0.1960206 ]]\n"
     ]
    }
   ],
   "source": [
    "# Test case; compare your output with what is in the lab pdf\n",
    "beta, gamma = example_hmm.backward_pass(z_example)\n",
    "print(beta)\n",
    "print(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39109931 0.39359405 0.21530664]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "beta, gamma = stock_hmm.backward_pass(z)\n",
    "print(gamma[0])\n",
    "# print the most likely class\n",
    "print(np.argmax(gamma[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5\n",
    "Creating a method `viterbi_algorithm` in your HMM class to implement the Viterbi algorithm.\n",
    "This function should accept the observation sequence $\\mathbf{z}$ and return the most likely state sequence $\\mathbf{x}^*$.\n",
    "\n",
    "Test your function on the example HMM and compare output with the lab pdf.\n",
    "\n",
    "Apply your function to the stock market HMM from Problem 3.\n",
    "With the observaition sequence from `stocks.npy`, what is the most likely sequence of hidden states?\n",
    "Is the initial state of the most likely sequence the same as the most likely initial state you found in Problem 4?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Test case\n",
    "xstar = example_hmm.viterbi_algorithm(z_example)\n",
    "print(xstar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 1 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 1 0 0 0 1 2 2 2 2 2\n",
      " 2 2 2 2 2 2 1 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "xstar = stock_hmm.viterbi_algorithm(z)\n",
    "print(xstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most likely initialize state is 0 instead of 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6\n",
    "\n",
    "Train a `hmmlearn.hmm.CategoricalHMM` on `declaration.txt`. Use `N=2` states and `M=len(set(obs))=27` observation values (26 lower case characters and 1 whitespace character).\n",
    "Use `n_iter=200` and `tol=1e-4`.\n",
    "\n",
    "Once the learning algorithm converges, analyze the state observation matrix $B$. Note which rows correspond to the largest and smallest probability values in each column of $B$, and check the corresponding characters. The HMM should have detected a vowel state and a consonant state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_translate(a, my_dict):\n",
    "    # translate numpy array from symbols to state numbers or vice versa\n",
    "    return np.vectorize(my_dict.__getitem__)(a)\n",
    "\n",
    "def prep_data(filename):\n",
    "    \"\"\"\n",
    "    Reads in the file and prepares it for use in an HMM.\n",
    "    Returns:\n",
    "        symbols (dict): a dictionary that maps characters to their integer values\n",
    "        obs_sequence (ndarray): an array of integers representing the read-in text\n",
    "    \"\"\"\n",
    "    # Get the data as a single string\n",
    "    with codecs.open(filename, encoding='utf-8') as f:\n",
    "        data=f.read().lower()  # and convert to all lower case\n",
    "    # remove punctuation and newlines\n",
    "    remove_punct_map = {ord(char): \n",
    "                        None for char in string.punctuation+\"\\n\\r\"}\n",
    "    data = data.translate(remove_punct_map)\n",
    "    # make a list of the symbols in the data\n",
    "    symbols = sorted(list(set(data)))\n",
    "    # convert the data to a NumPy array of symbols\n",
    "    a = np.array(list(data))\n",
    "    # make a conversion dictionary from symbols to state numbers\n",
    "    symbols_to_obsstates = {x:i for i,x in enumerate(symbols)}\n",
    "    # convert the symbols in a to state numbers\n",
    "    obs_sequence = vec_translate(a,symbols_to_obsstates)\n",
    "    return symbols, obs_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols, obs = prep_data('declaration.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.1535, 0.1866\n",
      "a, 0.0619, 0.0592\n",
      "b, 0.0000, 0.0347\n",
      "c, 0.0301, 0.0112\n",
      "d, 0.0495, 0.0001\n",
      "e, 0.1306, 0.0710\n",
      "f, 0.0000, 0.0657\n",
      "g, 0.0256, 0.0000\n",
      "h, 0.0686, 0.0000\n",
      "i, 0.0883, 0.0000\n",
      "j, 0.0000, 0.0058\n",
      "k, 0.0028, 0.0000\n",
      "l, 0.0035, 0.0767\n",
      "m, 0.0152, 0.0244\n",
      "n, 0.0950, 0.0000\n",
      "o, 0.0304, 0.1307\n",
      "p, 0.0000, 0.0503\n",
      "q, 0.0000, 0.0022\n",
      "r, 0.0234, 0.1117\n",
      "s, 0.0684, 0.0474\n",
      "t, 0.1156, 0.0191\n",
      "u, 0.0053, 0.0664\n",
      "v, 0.0146, 0.0000\n",
      "w, 0.0156, 0.0065\n",
      "x, 0.0014, 0.0006\n",
      "y, 0.0000, 0.0295\n",
      "z, 0.0008, 0.0000\n"
     ]
    }
   ],
   "source": [
    "from hmmlearn import hmm\n",
    "\n",
    "h = hmm.CategoricalHMM(n_components=2, n_features = 27, tol=1e-4, n_iter=200, )\n",
    "h.fit(obs.reshape(-1,1))\n",
    "\n",
    "pi = h.startprob_\n",
    "A = h.transmat_.T\n",
    "B = h.emissionprob_.T\n",
    "\n",
    "for i in range(len(B)):\n",
    "    print(f\"{symbols[i]}, {B[i, 0]:0.4f}, {B[i, 1]:0.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 7\n",
    "\n",
    "Repeat the same calculation with `WarAndPeace.txt` with 2 hidden states. Interpret/explain your results. Which Cyrillic characters appear to be vowels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols, obs = prep_data('WarAndPeace.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " , 0.1711, 0.1608\n",
      "а, 0.1902, 0.0169\n",
      "б, 0.0000, 0.0217\n",
      "в, 0.0288, 0.0440\n",
      "г, 0.0044, 0.0237\n",
      "д, 0.0087, 0.0296\n",
      "е, 0.0000, 0.0980\n",
      "ж, 0.0047, 0.0100\n",
      "з, 0.0492, 0.0000\n",
      "и, 0.0731, 0.0448\n",
      "й, 0.0000, 0.0130\n",
      "к, 0.0731, 0.0112\n",
      "л, 0.0685, 0.0319\n",
      "м, 0.0100, 0.0286\n",
      "н, 0.0795, 0.0491\n",
      "о, 0.0000, 0.1390\n",
      "п, 0.0026, 0.0325\n",
      "р, 0.0144, 0.0454\n",
      "с, 0.0598, 0.0341\n",
      "т, 0.0267, 0.0558\n",
      "у, 0.0111, 0.0292\n",
      "ф, 0.0039, 0.0000\n",
      "х, 0.0000, 0.0096\n",
      "ц, 0.0038, 0.0026\n",
      "ч, 0.0058, 0.0142\n",
      "ш, 0.0053, 0.0071\n",
      "щ, 0.0012, 0.0036\n",
      "ъ, 0.0000, 0.0004\n",
      "ы, 0.0000, 0.0217\n",
      "ь, 0.0321, 0.0115\n",
      "э, 0.0000, 0.0038\n",
      "ю, 0.0046, 0.0062\n",
      "я, 0.0675, 0.0000\n",
      "ё, 0.0000, 0.0001\n"
     ]
    }
   ],
   "source": [
    "h = hmm.CategoricalHMM(n_components=2, tol=1e-4, n_iter=200, )\n",
    "h.fit(obs.reshape(-1,1))\n",
    "\n",
    "pi = h.startprob_\n",
    "A = h.transmat_.T\n",
    "B = h.emissionprob_.T\n",
    "\n",
    "for i in range(len(B)):\n",
    "    print(f\"{symbols[i]}, {B[i, 0]:0.4f}, {B[i, 1]:0.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data provided, the Cyrillic characters а, е, и, о, у, ы, э, ю, я, and ё show as vowels. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
